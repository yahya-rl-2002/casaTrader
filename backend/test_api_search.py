#!/usr/bin/env python3
"""
Script pour rechercher et tester les APIs disponibles pour la Bourse de Casablanca
"""
import sys
sys.path.append('.')

import requests
from bs4 import BeautifulSoup
import json


def test_casablanca_bourse_api():
    """Tester si la Bourse de Casablanca a une API publique"""
    print("ğŸ” Recherche d'API - Bourse de Casablanca")
    print("=" * 60)
    
    base_urls = [
        "https://www.casablanca-bourse.com",
        "https://api.casablanca-bourse.com",
        "https://www.casablanca-bourse.com/api",
    ]
    
    session = requests.Session()
    session.verify = False
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    })
    
    import urllib3
    urllib3.disable_warnings()
    
    for url in base_urls:
        print(f"\nğŸŒ Test: {url}")
        try:
            response = session.get(url, timeout=10)
            print(f"   âœ… Status: {response.status_code}")
            print(f"   ğŸ“Š Content-Type: {response.headers.get('content-type', 'N/A')}")
            
            # Chercher des patterns d'API
            if 'application/json' in response.headers.get('content-type', ''):
                print(f"   ğŸ¯ RÃ©ponse JSON dÃ©tectÃ©e!")
                try:
                    data = response.json()
                    print(f"   ğŸ“¦ ClÃ©s: {list(data.keys())[:5]}")
                except:
                    pass
        except Exception as e:
            print(f"   âŒ Erreur: {e}")


def search_for_api_endpoints():
    """Chercher des endpoints API dans le HTML"""
    print("\n\nğŸ” Recherche d'endpoints API dans le code source")
    print("=" * 60)
    
    session = requests.Session()
    session.verify = False
    import urllib3
    urllib3.disable_warnings()
    
    try:
        response = session.get("https://www.casablanca-bourse.com/fr/live-market/indices/MASI", timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Chercher des scripts
        scripts = soup.find_all('script')
        print(f"\nğŸ“œ {len(scripts)} scripts trouvÃ©s")
        
        api_patterns = ['api', 'endpoint', 'fetch', 'ajax', 'data']
        
        for i, script in enumerate(scripts):
            script_content = script.string if script.string else ''
            
            for pattern in api_patterns:
                if pattern in script_content.lower():
                    # Extraire les URLs potentielles
                    import re
                    urls = re.findall(r'https?://[^\s<>"]+|/api/[^\s<>"]+', script_content)
                    if urls:
                        print(f"\n   Script #{i} - Pattern '{pattern}' trouvÃ©:")
                        for url in urls[:3]:
                            print(f"      ğŸ”— {url}")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")


def test_known_financial_apis():
    """Tester des APIs financiÃ¨res connues"""
    print("\n\nğŸ’¼ Test d'APIs financiÃ¨res alternatives")
    print("=" * 60)
    
    apis = {
        "Alpha Vantage": "https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol=IBM&apikey=demo",
        "Yahoo Finance": "https://query1.finance.yahoo.com/v8/finance/chart/AAPL",
        "Investing.com": "https://www.investing.com/indices/morocco-all-shares",
    }
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    })
    
    for name, url in apis.items():
        print(f"\nğŸŒ {name}")
        print(f"   URL: {url}")
        try:
            response = session.get(url, timeout=10)
            print(f"   âœ… Status: {response.status_code}")
            
            if response.status_code == 200:
                content_type = response.headers.get('content-type', '')
                if 'json' in content_type:
                    print(f"   ğŸ¯ API JSON disponible!")
                    try:
                        data = response.json()
                        print(f"   ğŸ“¦ Structure: {list(data.keys())[:5] if isinstance(data, dict) else 'Array'}")
                    except:
                        pass
                else:
                    print(f"   ğŸ“„ Type: {content_type}")
        except Exception as e:
            print(f"   âŒ Erreur: {type(e).__name__}")


def analyze_page_structure():
    """Analyser la structure de la page pour mieux comprendre les donnÃ©es"""
    print("\n\nğŸ“Š Analyse de la structure de la page")
    print("=" * 60)
    
    session = requests.Session()
    session.verify = False
    import urllib3
    urllib3.disable_warnings()
    
    try:
        response = session.get("https://www.casablanca-bourse.com/fr/live-market/indices/MASI", timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print("\nğŸ” Ã‰lÃ©ments clÃ©s trouvÃ©s:")
        
        # Tables
        tables = soup.find_all('table')
        print(f"\n   ğŸ“Š Tables: {len(tables)}")
        for i, table in enumerate(tables[:2]):
            print(f"      Table #{i}:")
            print(f"         Classes: {table.get('class', [])}")
            rows = table.find_all('tr')
            print(f"         Lignes: {len(rows)}")
            if rows:
                cols = rows[0].find_all(['th', 'td'])
                print(f"         Colonnes: {len(cols)}")
        
        # Divs avec classes intÃ©ressantes
        interesting_classes = ['price', 'value', 'data', 'quote', 'market', 'index']
        print(f"\n   ğŸ¯ Divs avec classes intÃ©ressantes:")
        for cls in interesting_classes:
            divs = soup.find_all('div', class_=lambda x: x and cls in str(x).lower())
            if divs:
                print(f"      '{cls}': {len(divs)} trouvÃ©(s)")
        
        # Scripts avec donnÃ©es JSON
        print(f"\n   ğŸ“œ Scripts avec donnÃ©es:")
        scripts = soup.find_all('script')
        for i, script in enumerate(scripts):
            if script.string and ('__NEXT_DATA__' in script.string or 'window.' in script.string):
                print(f"      Script #{i}: Contient des donnÃ©es possibles")
                if '__NEXT_DATA__' in script.string:
                    print(f"         ğŸ¯ Next.js data trouvÃ©!")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")


def main():
    """Fonction principale"""
    print("ğŸš€ Recherche d'APIs pour la Bourse de Casablanca")
    print("=" * 60)
    
    test_casablanca_bourse_api()
    search_for_api_endpoints()
    analyze_page_structure()
    test_known_financial_apis()
    
    print("\n\nğŸ“‹ RÃ©sumÃ© des Recommandations")
    print("=" * 60)
    print("""
    1ï¸âƒ£ Bourse de Casablanca:
       - âœ… Connexion SSL rÃ©solue
       - âš ï¸ Pas d'API publique Ã©vidente
       - ğŸ’¡ Utiliser le scraping web amÃ©liorÃ©
    
    2ï¸âƒ£ APIs Alternatives:
       - Alpha Vantage (nÃ©cessite clÃ© API)
       - Yahoo Finance (donnÃ©es limitÃ©es)
       - Investing.com (scraping nÃ©cessaire)
    
    3ï¸âƒ£ Solution RecommandÃ©e:
       - Scraping web avec fallback intelligent
       - Cache des donnÃ©es pour rÃ©duire les requÃªtes
       - Mise Ã  jour pÃ©riodique (ex: toutes les heures)
    
    4ï¸âƒ£ Pour la Production:
       - Contacter la Bourse de Casablanca pour un accÃ¨s API
       - Utiliser un service de donnÃ©es financiÃ¨res payant
       - ImplÃ©menter un systÃ¨me de cache robuste
    """)


if __name__ == "__main__":
    main()








