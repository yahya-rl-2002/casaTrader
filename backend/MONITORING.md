# üìä Monitoring et Observabilit√©

## ‚úÖ Impl√©mentation Compl√®te

Le syst√®me dispose maintenant d'un syst√®me complet de monitoring et observabilit√© avec :
- **M√©triques Prometheus** pour le monitoring des performances
- **Logging structur√©** pour une meilleure tra√ßabilit√©
- **Health checks avanc√©s** pour la surveillance de l'√©tat du syst√®me
- **Endpoints de monitoring** pour l'int√©gration avec des outils externes

---

## üìã Structure

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitoring.py      # M√©triques Prometheus et helpers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging.py         # Logging structur√© am√©lior√©
‚îÇ   ‚îî‚îÄ‚îÄ api/v1/endpoints/
‚îÇ       ‚îî‚îÄ‚îÄ monitoring.py       # Endpoints de monitoring
‚îî‚îÄ‚îÄ MONITORING.md              # Cette documentation
```

---

## üéØ M√©triques Prometheus

### M√©triques HTTP

- **`http_requests_total`** : Nombre total de requ√™tes HTTP (par m√©thode, endpoint, status)
- **`http_request_duration_seconds`** : Dur√©e des requ√™tes HTTP (histogramme)
- **`http_requests_in_flight`** : Nombre de requ√™tes en cours
- **`http_errors_total`** : Nombre d'erreurs HTTP (par type)

### M√©triques Base de Donn√©es

- **`db_queries_total`** : Nombre total de requ√™tes DB (par op√©ration, table)
- **`db_query_duration_seconds`** : Dur√©e des requ√™tes DB (histogramme)

### M√©triques Scraping

- **`scraping_requests_total`** : Nombre de requ√™tes de scraping (par source, status)
- **`scraping_duration_seconds`** : Dur√©e des scrapings (histogramme)

### M√©triques Cache

- **`cache_hits_total`** : Nombre de cache hits
- **`cache_misses_total`** : Nombre de cache misses
- **`cache_operations_total`** : Nombre total d'op√©rations cache (par op√©ration, type)

### M√©triques Pipeline

- **`pipeline_runs_total`** : Nombre d'ex√©cutions de pipeline (par status)
- **`pipeline_duration_seconds`** : Dur√©e d'ex√©cution du pipeline

### M√©triques Sentiment

- **`sentiment_analyses_total`** : Nombre d'analyses de sentiment (par m√©thode, status)
- **`sentiment_analysis_duration_seconds`** : Dur√©e des analyses de sentiment

---

## üîå Endpoints de Monitoring

### 1. M√©triques Prometheus

**GET** `/api/v1/monitoring/metrics`

Retourne les m√©triques au format Prometheus.

```bash
curl http://localhost:8001/api/v1/monitoring/metrics
```

**Exemple de r√©ponse** :
```
# HELP http_requests_total Total number of HTTP requests
# TYPE http_requests_total counter
http_requests_total{endpoint="/api/v1/media/latest",method="GET",status_code="200"} 42.0
http_request_duration_seconds_bucket{endpoint="/api/v1/media/latest",method="GET",le="0.005"} 35.0
...
```

### 2. Health Check Complet

**GET** `/api/v1/monitoring/health`

V√©rifie la sant√© compl√®te du syst√®me :
- Statut g√©n√©ral de l'API
- Connexion √† la base de donn√©es
- Statut du cache
- Statut du scheduler

```bash
curl http://localhost:8001/api/v1/monitoring/health
```

**Exemple de r√©ponse** :
```json
{
  "overall": {
    "status": "healthy",
    "timestamp": "2025-11-15T14:30:00",
    "version": "0.1.0",
    "environment": "development",
    "uptime_seconds": 3600.5
  },
  "database": {
    "status": "healthy",
    "response_time_ms": 2.5
  },
  "cache": {
    "status": "available",
    "stats": {
      "hits": 1234,
      "misses": 567,
      "size": 100
    }
  },
  "scheduler": {
    "status": "running",
    "active_jobs": 2,
    "jobs": [
      {
        "id": "index_update_10min",
        "next_run": "2025-11-15T14:40:00"
      }
    ]
  }
}
```

### 3. Health Check Base de Donn√©es

**GET** `/api/v1/monitoring/health/database`

V√©rifie uniquement la sant√© de la base de donn√©es.

```bash
curl http://localhost:8001/api/v1/monitoring/health/database
```

### 4. Ping Simple

**GET** `/api/v1/monitoring/health/ping`

Ping simple pour v√©rifier que l'API r√©pond (utilis√© par les load balancers).

```bash
curl http://localhost:8001/api/v1/monitoring/health/ping
```

### 5. Statistiques du Syst√®me

**GET** `/api/v1/monitoring/stats`

Statistiques d√©taill√©es du syst√®me :
- Statistiques de la base de donn√©es
- Statistiques du cache
- Statistiques du scheduler

```bash
curl http://localhost:8001/api/v1/monitoring/stats
```

**Exemple de r√©ponse** :
```json
{
  "timestamp": "2025-11-15T14:30:00",
  "database": {
    "media_articles_count": 1234,
    "index_scores_count": 567,
    "latest_score": {
      "score": 65.5,
      "as_of": "2025-11-15T14:00:00"
    }
  },
  "cache": {
    "hits": 1234,
    "misses": 567,
    "hit_rate": 0.68
  },
  "scheduler": {
    "active_jobs": 2,
    "jobs": [
      {
        "id": "index_update_10min",
        "next_run": "2025-11-15T14:40:00"
      }
    ]
  }
}
```

---

## üîß Utilisation dans le Code

### Tracker une Requ√™te HTTP

Le middleware `metrics_middleware` track automatiquement toutes les requ√™tes HTTP. Aucune action n√©cessaire.

### Tracker une Requ√™te DB

```python
from app.core.monitoring import track_db_query

with track_db_query("SELECT", "media_articles"):
    articles = db.query(MediaArticle).all()
```

### Tracker un Scraping

```python
from app.core.monitoring import track_scraping, scraping_requests_total

with track_scraping("hespress"):
    # Code de scraping
    scraping_requests_total.labels(source="hespress", status="success").inc()
```

### Tracker le Cache

```python
from app.core.monitoring import track_cache_hit, track_cache_miss, track_cache_set

# Dans cache_service.py
if cached_value:
    track_cache_hit("media")
    return cached_value
else:
    track_cache_miss("media")
    # ... calculer la valeur ...
    track_cache_set("media")
    return value
```

### Tracker le Pipeline

```python
from app.core.monitoring import track_pipeline_run, pipeline_duration_seconds
import time

start_time = time.time()
try:
    # Ex√©cuter le pipeline
    result = run_pipeline()
    track_pipeline_run("success")
except Exception as e:
    track_pipeline_run("error")
    raise
finally:
    duration = time.time() - start_time
    pipeline_duration_seconds.observe(duration)
```

---

## üìä Int√©gration avec Prometheus

### Configuration Prometheus

Ajoutez cette configuration dans `prometheus.yml` :

```yaml
scrape_configs:
  - job_name: 'fear-greed-api'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:8001']
    metrics_path: '/api/v1/monitoring/metrics'
```

### Grafana Dashboard

Cr√©ez un dashboard Grafana avec les m√©triques suivantes :

1. **Requ√™tes HTTP par seconde**
   ```
   rate(http_requests_total[5m])
   ```

2. **Latence P95 des requ√™tes**
   ```
   histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
   ```

3. **Taux d'erreur**
   ```
   rate(http_errors_total[5m]) / rate(http_requests_total[5m])
   ```

4. **Cache hit rate**
   ```
   rate(cache_hits_total[5m]) / (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m]))
   ```

5. **Dur√©e du pipeline**
   ```
   histogram_quantile(0.95, rate(pipeline_duration_seconds_bucket[5m]))
   ```

---

## üìù Logging Structur√©

### Configuration

Le logging structur√© peut √™tre activ√© via les settings :

```python
# Dans app/core/config.py
logging_json_format: bool = False  # Activer pour JSON
logging_level: str = "INFO"
```

### Utilisation

```python
from app.core.logging import get_logger

logger = get_logger(__name__)

# Logging standard
logger.info("Processing article", extra={
    "article_id": article.id,
    "source": article.source
})

# Avec structlog (si disponible)
logger = get_structured_logger(__name__)
logger.bind(article_id=article.id, source=article.source).info("Processing article")
```

---

## üö® Alertes Recommand√©es

### Alertes Critiques

1. **API Down**
   ```
   up{job="fear-greed-api"} == 0
   ```

2. **Taux d'erreur √©lev√©**
   ```
   rate(http_errors_total[5m]) / rate(http_requests_total[5m]) > 0.05
   ```

3. **Latence √©lev√©e**
   ```
   histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1.0
   ```

4. **Base de donn√©es inaccessible**
   ```
   monitoring_database_status{status="unhealthy"} == 1
   ```

### Alertes de Performance

1. **Cache hit rate faible**
   ```
   rate(cache_hits_total[5m]) / (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m])) < 0.5
   ```

2. **Pipeline lent**
   ```
   histogram_quantile(0.95, rate(pipeline_duration_seconds_bucket[5m])) > 300
   ```

3. **Scraping √©chouant**
   ```
   rate(scraping_requests_total{status="error"}[5m]) > 0
   ```

---

## üîç D√©pannage

### M√©triques non visibles

**Probl√®me** : Les m√©triques n'apparaissent pas dans Prometheus

**Solutions** :
1. V√©rifier que le middleware est activ√© dans `app/main.py`
2. V√©rifier l'endpoint `/api/v1/monitoring/metrics`
3. V√©rifier la configuration Prometheus

### Health check √©choue

**Probl√®me** : Le health check retourne "unhealthy"

**Solutions** :
1. V√©rifier les logs pour les erreurs sp√©cifiques
2. V√©rifier la connexion √† la base de donn√©es
3. V√©rifier la configuration du cache
4. V√©rifier le scheduler

### Performance d√©grad√©e

**Probl√®me** : Les m√©triques montrent une performance d√©grad√©e

**Solutions** :
1. Analyser les m√©triques de latence
2. V√©rifier le cache hit rate
3. V√©rifier les requ√™tes DB lentes
4. V√©rifier les scrapings qui √©chouent

---

## üìö Ressources

- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Dashboards](https://grafana.com/grafana/dashboards/)
- [Structlog Documentation](https://www.structlog.org/)

---

**Date**: 2025-11-15  
**Version**: 1.0.0  
**Statut**: ‚úÖ Impl√©ment√© et Op√©rationnel



