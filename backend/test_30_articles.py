#!/usr/bin/env python3
"""
Test du MediaScraper avec 20-30 articles (3 sources)
"""
import sys
sys.path.append('.')

from app.pipelines.ingestion.media_scraper import MediaScraper
from app.services.sentiment_service import SentimentAnalyzer


def main():
    print("\nğŸ¯ TEST - 20-30 ARTICLES DE 3 SOURCES")
    print("=" * 80)
    print("Medias24 + BourseNews + Challenge + La Vie Ã‰co + L'Ã‰conomiste")
    print("=" * 80)
    
    # CrÃ©er le scraper
    print("\nğŸ“° Initialisation du scraper multi-sources...")
    scraper = MediaScraper()
    
    # Scraper avec 10 articles par source = 30 articles total
    print("\nğŸŒ Scraping de TOUTES les sources (10 articles/source)...")
    print("-" * 80)
    
    articles = scraper.scrape_all_sources(max_articles_per_source=10)
    
    print(f"\nâœ… {len(articles)} articles TOTAUX rÃ©cupÃ©rÃ©s")
    
    # Statistiques par source
    by_source = {}
    for article in articles:
        if article.source not in by_source:
            by_source[article.source] = []
        by_source[article.source].append(article)
    
    print(f"\nğŸ“Š RÃ©partition par source:")
    print("-" * 60)
    for source, arts in sorted(by_source.items(), key=lambda x: -len(x[1])):
        percentage = (len(arts) / len(articles) * 100) if articles else 0
        bar_length = int(percentage / 2)  # Bar de 50 caractÃ¨res max
        bar = "â–ˆ" * bar_length
        print(f"   {source.upper():20} : {len(arts):2} articles ({percentage:5.1f}%) {bar}")
    
    # Statistiques globales
    print(f"\nğŸ“ˆ Statistiques Globales:")
    print("-" * 60)
    print(f"   â€¢ Total articles: {len(articles)}")
    print(f"   â€¢ Sources actives: {len(by_source)}")
    print(f"   â€¢ Moyenne par source: {len(articles) / len(by_source):.1f}")
    
    # Afficher quelques articles de chaque source
    print(f"\n\nğŸ“° Exemples d'Articles par Source")
    print("=" * 80)
    
    for source in sorted(by_source.keys()):
        source_articles = by_source[source]
        emoji = {"medias24": "ğŸ“°", "boursenews": "ğŸ“Š", "leconomiste": "ğŸ’¼", "challenge": "ğŸ“Œ", "lavieeco": "ğŸ“°"}.get(source, "ğŸ“Œ")
        
        print(f"\n{emoji} {source.upper()} ({len(source_articles)} articles)")
        print("-" * 60)
        
        for i, article in enumerate(source_articles[:3], 1):
            print(f"   {i}. {article.title[:65]}...")
            print(f"      ğŸ”— {article.url[:70]}...")
    
    # Analyse de sentiment
    if articles:
        print(f"\n\nğŸ§  Analyse de Sentiment")
        print("=" * 80)
        
        print(f"\nğŸ” Analyse de sentiment sur {len(articles)} articles...")
        
        analyzer = SentimentAnalyzer()
        analyzer.analyze_articles(articles)
        
        # Statistiques globales
        positive_count = sum(1 for a in articles if a.sentiment_score and a.sentiment_score > 10)
        negative_count = sum(1 for a in articles if a.sentiment_score and a.sentiment_score < -10)
        neutral_count = len(articles) - positive_count - negative_count
        
        avg_sentiment = sum(a.sentiment_score for a in articles if a.sentiment_score) / len(articles) if articles else 0
        
        print(f"\nğŸ“Š Distribution Globale:")
        total = len(articles)
        print(f"   â€¢ Positifs: {positive_count:2} articles ğŸ˜Š ({positive_count/total*100:5.1f}%)")
        print(f"   â€¢ NÃ©gatifs: {negative_count:2} articles ğŸ˜Ÿ ({negative_count/total*100:5.1f}%)")
        print(f"   â€¢ Neutres:  {neutral_count:2} articles ğŸ˜ ({neutral_count/total*100:5.1f}%)")
        print(f"   â€¢ Score moyen: {avg_sentiment:+.2f}")
        
        # Statistiques par source
        print(f"\nğŸ“Š Sentiment par Source:")
        for source, arts in sorted(by_source.items()):
            source_articles = [a for a in articles if a.source == source]
            if source_articles:
                avg_source_sentiment = sum(a.sentiment_score for a in source_articles if a.sentiment_score) / len(source_articles)
                emoji = {"medias24": "ğŸ“°", "boursenews": "ğŸ“Š", "leconomiste": "ğŸ’¼", "challenge": "ğŸ“Œ", "lavieeco": "ğŸ“°"}.get(source, "ğŸ“Œ")
                mood = "ğŸ˜Š" if avg_source_sentiment > 10 else "ğŸ˜Ÿ" if avg_source_sentiment < -10 else "ğŸ˜"
                print(f"   {emoji} {source.upper():20} : {avg_source_sentiment:+6.2f} {mood}")
    
    # RÃ©sumÃ© final
    print(f"\n\nâœ… RÃ‰SUMÃ‰ FINAL")
    print("=" * 80)
    
    print(f"\nğŸ‰ Objectif Atteint:")
    target = "20-30"
    status = "âœ… SUCCÃˆS" if 20 <= len(articles) <= 30 else f"âš ï¸  {len(articles)} articles (objectif: 20-30)"
    print(f"   Objectif: {target} articles")
    print(f"   RÃ©sultat: {len(articles)} articles")
    print(f"   Status: {status}")
    
    print(f"\nğŸ“Š Sources Actives:")
    emoji_map = {"medias24": "ğŸ“°", "boursenews": "ğŸ“Š", "leconomiste": "ğŸ’¼", "challenge": "ğŸ“Œ", "lavieeco": "ğŸ“°"}
    for source in sorted(by_source.keys()):
        emoji = emoji_map.get(source, "ğŸ“Œ")
        print(f"   {emoji} {source.upper()}: {len(by_source[source])} articles")
    
    print(f"\nğŸ’¡ QualitÃ©:")
    print(f"   âœ… Scraping multi-sources ({len(by_source)} sources)")
    print(f"   âœ… Articles uniques ({len(articles)})")
    print(f"   âœ… Sentiment analysÃ©")
    print(f"   âœ… Anti-blocage actif")
    print(f"   âœ… DonnÃ©es 100% rÃ©elles")
    
    print(f"\nğŸš€ Le systÃ¨me est prÃªt avec {len(articles)} articles de {len(by_source)} sources !")
    print("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Test interrompu")
    except Exception as e:
        print(f"\n\nâŒ Erreur: {e}")
        import traceback
        traceback.print_exc()


