#!/usr/bin/env python3
"""
Script de test pour vÃ©rifier la rÃ©cupÃ©ration de donnÃ©es rÃ©elles
"""
import sys
sys.path.append('.')

from app.pipelines.ingestion.market_scraper import CasablancaMarketScraper
from app.pipelines.ingestion.media_scraper import MediaScraper
from app.services.sentiment_service import SentimentAnalyzer


def test_market_data():
    """Test du scraping des donnÃ©es de marchÃ©"""
    print("ğŸ” Test du scraping de la Bourse de Casablanca...")
    print("=" * 60)
    
    scraper = CasablancaMarketScraper()
    
    # Test 1: DonnÃ©es en direct
    print("\n1ï¸âƒ£ RÃ©cupÃ©ration des donnÃ©es en direct...")
    try:
        live_data = scraper.fetch_live_data()
        if live_data:
            print(f"âœ… {len(live_data)} donnÃ©es rÃ©cupÃ©rÃ©es")
            for data in live_data[:3]:  # Afficher les 3 premiÃ¨res
                print(f"   - {data.symbol}: {data.last_price:.2f} MAD ({data.change_percent:+.2f}%)")
                print(f"     Volume: {data.volume:,} | Date: {data.as_of}")
        else:
            print("âš ï¸ Aucune donnÃ©e rÃ©cupÃ©rÃ©e (peut-Ãªtre en fallback)")
    except Exception as e:
        print(f"âŒ Erreur: {e}")
    
    # Test 2: DonnÃ©es historiques
    print("\n2ï¸âƒ£ RÃ©cupÃ©ration des donnÃ©es historiques (30 jours)...")
    try:
        historical_data = scraper.fetch_historical_data(days=30)
        if historical_data:
            print(f"âœ… {len(historical_data)} jours de donnÃ©es")
            # Afficher les 3 derniers jours
            for data in historical_data[-3:]:
                print(f"   - {data.date}: Close={data.close_price:.2f}, Volume={data.volume:,}")
        else:
            print("âš ï¸ Aucune donnÃ©e historique")
    except Exception as e:
        print(f"âŒ Erreur: {e}")


def test_media_data():
    """Test du scraping des mÃ©dias"""
    print("\n\nğŸ“° Test du scraping des mÃ©dias marocains...")
    print("=" * 60)
    
    scraper = MediaScraper()
    
    print("\nRÃ©cupÃ©ration des articles...")
    try:
        articles = scraper.scrape_all_sources(max_articles_per_source=5)
        
        if articles:
            print(f"âœ… {len(articles)} articles rÃ©cupÃ©rÃ©s")
            for i, article in enumerate(articles[:5], 1):
                print(f"\n   Article {i}:")
                print(f"   ğŸ“° Titre: {article.title[:60]}...")
                print(f"   ğŸŒ Source: {article.source}")
                print(f"   ğŸ“… Date: {article.published_at}")
                print(f"   ğŸ”— URL: {article.url[:50]}...")
        else:
            print("âš ï¸ Aucun article rÃ©cupÃ©rÃ© (utilise des donnÃ©es fallback)")
    except Exception as e:
        print(f"âŒ Erreur: {e}")


def test_sentiment_analysis():
    """Test de l'analyse de sentiment"""
    print("\n\nğŸ§  Test de l'analyse de sentiment...")
    print("=" * 60)
    
    analyzer = SentimentAnalyzer()
    
    test_texts = [
        "La bourse de Casablanca affiche une croissance exceptionnelle avec des performances remarquables",
        "Crise Ã©conomique majeure avec des difficultÃ©s importantes sur le marchÃ© financier",
        "Le marchÃ© reste stable avec des volumes moyens et une volatilitÃ© normale"
    ]
    
    for i, text in enumerate(test_texts, 1):
        result = analyzer.analyze_text(text)
        print(f"\n   Test {i}:")
        print(f"   ğŸ“ Texte: {text[:60]}...")
        print(f"   ğŸ“Š PolaritÃ©: {result.polarity:.3f} ({analyzer.get_sentiment_label(result.polarity)})")
        print(f"   ğŸ¯ Confiance: {result.confidence:.3f}")
        print(f"   âœ… Mots positifs: {', '.join(result.positive_words[:5])}")
        print(f"   âŒ Mots nÃ©gatifs: {', '.join(result.negative_words[:5])}")


def test_real_scraping():
    """Test du vrai scraping web"""
    print("\n\nğŸŒ Test du scraping web rÃ©el...")
    print("=" * 60)
    
    scraper = CasablancaMarketScraper()
    
    print("\nTentative de connexion Ã  www.casablanca-bourse.com...")
    try:
        import requests
        response = scraper.session.get(scraper.MARKET_URL, timeout=10)
        
        print(f"âœ… Connexion rÃ©ussie!")
        print(f"   Status Code: {response.status_code}")
        print(f"   Content Length: {len(response.content)} bytes")
        print(f"   Content Type: {response.headers.get('content-type', 'N/A')}")
        
        # Tenter de parser
        print("\n   Parsing du contenu...")
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Chercher des Ã©lÃ©ments intÃ©ressants
        title = soup.find('title')
        if title:
            print(f"   Titre de la page: {title.get_text()[:100]}")
        
        # Chercher des tables
        tables = soup.find_all('table')
        print(f"   Tables trouvÃ©es: {len(tables)}")
        
        # Chercher "MASI"
        masi_mentions = soup.find_all(text=lambda t: t and 'MASI' in t.upper())
        print(f"   Mentions de 'MASI': {len(masi_mentions)}")
        
        if masi_mentions:
            print(f"   Exemples: {[str(m)[:50] for m in masi_mentions[:3]]}")
        
    except Exception as e:
        print(f"âŒ Erreur de connexion: {e}")
        print(f"   Type: {type(e).__name__}")


def main():
    """Fonction principale"""
    print("ğŸš€ Test de RÃ©cupÃ©ration de DonnÃ©es RÃ©elles")
    print("=" * 60)
    print("Ce script teste la capacitÃ© Ã  rÃ©cupÃ©rer des donnÃ©es rÃ©elles")
    print("depuis la Bourse de Casablanca et les mÃ©dias marocains")
    print("=" * 60)
    
    # Tests
    test_real_scraping()
    test_market_data()
    test_media_data()
    test_sentiment_analysis()
    
    print("\n\nâœ… Tests terminÃ©s!")
    print("=" * 60)
    print("\nğŸ’¡ Conseils:")
    print("   - Si le scraping web Ã©choue, vÃ©rifiez votre connexion internet")
    print("   - Les donnÃ©es de fallback sont normales en cas d'Ã©chec")
    print("   - Pour la production, utilisez une API officielle si disponible")


if __name__ == "__main__":
    main()








