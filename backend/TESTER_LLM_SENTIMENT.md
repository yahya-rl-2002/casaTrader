# ğŸ¤– Guide d'Installation et Test du LLM Sentiment Analysis

## âœ… VÃ©rification de l'Installation

Le systÃ¨me LLM a Ã©tÃ© intÃ©grÃ© avec succÃ¨s ! Voici comment l'utiliser :

---

## ğŸ“‹ Ã‰tapes d'Installation

### 1ï¸âƒ£ Installer le package OpenAI

Le package `openai` est **dÃ©jÃ  installÃ©** dans votre environnement Poetry.

Pour vÃ©rifier :
```bash
cd "/Volumes/YAHYA SSD/Documents/fear and/backend"
source .venv/bin/activate
poetry show openai
```

Si ce n'est pas installÃ©, ajoutez-le :
```bash
poetry add openai
```

---

### 2ï¸âƒ£ Obtenir votre clÃ© API OpenAI

#### Option A : Si vous avez dÃ©jÃ  un compte OpenAI
1. Allez sur https://platform.openai.com/api-keys
2. Connectez-vous
3. Cliquez sur **"Create new secret key"**
4. Copiez la clÃ© (commence par `sk-proj-...`)

#### Option B : Si vous n'avez pas de compte
1. CrÃ©ez un compte sur https://platform.openai.com/signup
2. Ajoutez des crÃ©dits (minimum $5)
3. GÃ©nÃ©rez une clÃ© API

âš ï¸ **Important** : Gardez votre clÃ© secrÃ¨te ! Ne la partagez jamais.

---

### 3ï¸âƒ£ Configurer la ClÃ© API

#### Option A : Variable d'environnement temporaire (pour tester)
```bash
cd "/Volumes/YAHYA SSD/Documents/fear and/backend"
source .venv/bin/activate

# Remplacez YOUR_API_KEY par votre vraie clÃ©
export OPENAI_API_KEY='sk-proj-...'

# VÃ©rification
echo $OPENAI_API_KEY
```

#### Option B : Fichier .env permanent (recommandÃ©)
```bash
cd "/Volumes/YAHYA SSD/Documents/fear and/backend"

# CrÃ©ez un fichier .env
cat > .env << 'EOF'
OPENAI_API_KEY=sk-proj-...
EOF

# Assurez-vous que .env est dans .gitignore
echo ".env" >> .gitignore
```

Puis modifiez `app/services/llm_sentiment_service.py` pour charger le `.env` :
```python
from dotenv import load_dotenv
load_dotenv()  # Ajouter au dÃ©but du fichier
```

Installez python-dotenv si nÃ©cessaire :
```bash
poetry add python-dotenv
```

---

## ğŸ§ª Tester le LLM

### Test 1 : Script de Test Unitaire
```bash
cd "/Volumes/YAHYA SSD/Documents/fear and/backend"
source .venv/bin/activate

# Configurez votre clÃ© (si pas dÃ©jÃ  fait)
export OPENAI_API_KEY='sk-proj-...'

# Lancez le test
python test_llm_sentiment.py
```

**RÃ©sultat attendu** :
```
ğŸ¤– Test du LLM Sentiment Analyzer
================================

ğŸ“ Analyse de l'article 1/3...
Titre: La BMCI affiche une croissance record au T3 2025
Score: +0.75 (TrÃ¨s Positif)
Explication: L'article met en avant une forte croissance...

ğŸ“ Analyse de l'article 2/3...
Titre: Craintes de rÃ©cession sur le marchÃ© marocain
Score: -0.68 (NÃ©gatif)
Explication: Le ton de l'article est alarmiste...

ğŸ“Š Moyenne des sentiments: +0.23 â†’ 61.50/100
âœ… Test rÃ©ussi !
```

---

### Test 2 : Pipeline Complet avec LLM
```bash
cd "/Volumes/YAHYA SSD/Documents/fear and/backend"
source .venv/bin/activate
export OPENAI_API_KEY='sk-proj-...'

python test_complet_systeme.py
```

**Logs attendus** :
```
ğŸ¤– Using LLM (GPT) for sentiment analysis...
âœ… LLM sentiment analysis completed for 12 articles
ğŸ“Š Average sentiment (LLM): +0.35 â†’ 67.50/100
```

---

## ğŸ” Comment VÃ©rifier que le LLM Fonctionne

### 1. VÃ©rifier les logs
Cherchez ces emojis dans les logs :
- `ğŸ¤–` = LLM est activÃ©
- `âš ï¸` = LLM dÃ©sactivÃ©, utilise le dictionnaire
- `âŒ` = Erreur LLM
- `ğŸ”„` = Fallback vers dictionnaire

### 2. Comparer les scores
**Sans LLM (dictionnaire)** :
- BasÃ© sur des mots-clÃ©s franÃ§ais simples
- Score moyen souvent neutre (~50)
- Exemple : "hausse", "croissance" â†’ positif

**Avec LLM (GPT)** :
- Analyse contextuelle avancÃ©e
- Comprend les nuances et le sarcasme
- Scores plus prÃ©cis et variÃ©s
- Exemple : Peut dÃ©tecter qu'un article sur "hausse des dÃ©faillances" est nÃ©gatif

### 3. VÃ©rifier dans la base de donnÃ©es
```bash
cd "/Volumes/YAHYA SSD/Documents/fear and/backend"
source .venv/bin/activate

python << 'EOF'
from app.models.database import SessionLocal
from app.models.schemas import MediaArticle

db = SessionLocal()
articles = db.query(MediaArticle).order_by(MediaArticle.scraped_at.desc()).limit(5).all()

for article in articles:
    print(f"ğŸ“° {article.title[:50]}...")
    print(f"   Score: {article.sentiment_score:+.3f} | Label: {article.sentiment_label}")
    print()

db.close()
EOF
```

---

## âš™ï¸ Configuration AvancÃ©e

### Changer le modÃ¨le GPT
Dans `app/services/llm_sentiment_service.py` :
```python
def __init__(self, model: str = "gpt-4o-mini"):  # Par dÃ©faut
    # Options :
    # - gpt-4o-mini : Rapide et Ã©conomique (recommandÃ©)
    # - gpt-4o : Plus prÃ©cis mais plus cher
    # - gpt-3.5-turbo : Ã‰conomique mais moins bon en franÃ§ais
```

### DÃ©sactiver temporairement le LLM
Dans `app/services/pipeline_service.py` :
```python
def __init__(self, use_llm_sentiment: bool = False):  # Mettre False
```

Ou via variable d'environnement :
```bash
unset OPENAI_API_KEY  # DÃ©sactive automatiquement le LLM
```

---

## ğŸ’° CoÃ»ts EstimÃ©s

**ModÃ¨le gpt-4o-mini** (recommandÃ©) :
- **Prix** : $0.150 / 1M input tokens, $0.600 / 1M output tokens
- **Exemple** : 100 articles/jour Ã— 200 tokens/article
  - Input : ~20,000 tokens/jour = $0.003/jour
  - Output : ~5,000 tokens/jour = $0.003/jour
  - **Total : ~$0.18/mois** ğŸ“‰

**ModÃ¨le gpt-4o** :
- Plus cher (~10x), mais analyse plus fine
- **Total : ~$2/mois**

---

## ğŸš¨ DÃ©pannage

### Erreur : "Incorrect API key provided"
```bash
# VÃ©rifiez que votre clÃ© est correcte
echo $OPENAI_API_KEY

# La clÃ© doit commencer par sk-proj- ou sk-...
```

### Erreur : "Rate limit exceeded"
- Vous avez dÃ©passÃ© votre quota gratuit
- Ajoutez des crÃ©dits sur https://platform.openai.com/account/billing

### Le LLM n'est pas utilisÃ©
```bash
# VÃ©rifiez que la clÃ© est dÃ©finie
echo $OPENAI_API_KEY

# VÃ©rifiez les logs pour voir "ğŸ¤– Using LLM"
# Si vous voyez "âš ï¸ LLM not available", la clÃ© n'est pas configurÃ©e
```

### Erreur : "Module 'openai' not found"
```bash
cd "/Volumes/YAHYA SSD/Documents/fear and/backend"
poetry add openai
source .venv/bin/activate
```

---

## ğŸ¯ Recommandations

### Pour le dÃ©veloppement
1. **Utilisez le LLM** pour des analyses prÃ©cises
2. **Gardez le dictionnaire** comme fallback
3. **Testez rÃ©guliÃ¨rement** avec `test_llm_sentiment.py`

### Pour la production
1. **Configurez .env** avec votre clÃ© API
2. **Activez le LLM** dans `pipeline_service.py`
3. **Surveillez les coÃ»ts** sur https://platform.openai.com/usage

### Pour Ã©conomiser
1. **Utilisez gpt-4o-mini** (rapide + Ã©conomique)
2. **Limitez les articles** analysÃ©s (ex: 50/jour)
3. **Cachez les rÃ©sultats** pour ne pas rÃ©analyser les mÃªmes articles

---

## ğŸ“Š Comparaison : Dictionnaire vs LLM

| CritÃ¨re | Dictionnaire | LLM (GPT) |
|---------|--------------|-----------|
| **CoÃ»t** | âœ… Gratuit | ğŸ’° ~$0.20/mois |
| **Vitesse** | âœ… InstantanÃ© | â± 1-2s/article |
| **PrÃ©cision** | â­â­ Basique | â­â­â­â­â­ Excellente |
| **Contexte** | âŒ Ignore | âœ… Comprend |
| **Nuances** | âŒ Simples | âœ… Fines |
| **FranÃ§ais** | âš ï¸ LimitÃ© | âœ… Natif |
| **Setup** | âœ… Aucun | âš™ï¸ ClÃ© API |

---

## âœ… Checklist Finale

Avant de mettre en production :

- [ ] Package `openai` installÃ© (`poetry show openai`)
- [ ] ClÃ© API OpenAI configurÃ©e (`echo $OPENAI_API_KEY`)
- [ ] Test unitaire rÃ©ussi (`python test_llm_sentiment.py`)
- [ ] Pipeline complet OK (`python test_complet_systeme.py`)
- [ ] Logs montrent `ğŸ¤– Using LLM`
- [ ] Articles dans la DB ont des scores LLM
- [ ] Fallback fonctionne si pas de clÃ©
- [ ] CoÃ»ts surveillÃ©s sur OpenAI Platform

---

## ğŸ‰ Prochaines Ã‰tapes

Une fois le LLM testÃ© avec succÃ¨s :

1. **Automatisation** : Le scheduler exÃ©cutera le pipeline avec LLM toutes les 10 minutes
2. **Dashboard** : Les scores LLM seront affichÃ©s dans le frontend
3. **Monitoring** : Surveillez les coÃ»ts OpenAI dans votre tableau de bord

Voulez-vous que je vous aide Ã  configurer votre clÃ© API maintenant ? ğŸš€

