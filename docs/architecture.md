# ğŸ—ï¸ Architecture du SystÃ¨me

## Vue d'Ensemble

Le systÃ¨me Fear & Greed Index est une application full-stack qui calcule et expose un indice de sentiment du marchÃ© boursier marocain.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚  React + TypeScript
â”‚   (Port 8080)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend API   â”‚  FastAPI + Python
â”‚   (Port 8001)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
â”‚ SQLiteâ”‚ â”‚Redis â”‚  â”‚Scrapersâ”‚ â”‚Schedulerâ”‚
â”‚   DB  â”‚ â”‚Cache â”‚  â”‚        â”‚ â”‚ APSchedulerâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Composants Principaux

### 1. Backend API (FastAPI)

**ResponsabilitÃ©s** :
- Exposer les endpoints REST
- Calculer l'indice Fear & Greed
- GÃ©rer le scraping des mÃ©dias
- Orchestrer les pipelines de traitement
- GÃ©rer l'authentification et la sÃ©curitÃ©

**Structure** :
```
app/
â”œâ”€â”€ api/              # Endpoints REST
â”œâ”€â”€ core/             # Configuration, logging, monitoring
â”œâ”€â”€ models/           # ModÃ¨les de donnÃ©es (SQLAlchemy)
â”œâ”€â”€ pipelines/        # Pipelines de traitement
â”‚   â”œâ”€â”€ ingestion/    # Scrapers web
â”‚   â””â”€â”€ processing/   # Calculs des composantes
â”œâ”€â”€ services/          # Services mÃ©tier
â””â”€â”€ utils/            # Utilitaires
```

### 2. Frontend (React + TypeScript)

**ResponsabilitÃ©s** :
- Afficher le dashboard
- Visualiser les donnÃ©es historiques
- GÃ©rer l'interface utilisateur
- Appeler l'API backend

**Technologies** :
- React 18+
- TypeScript
- Tailwind CSS
- Recharts (graphiques)

### 3. Base de DonnÃ©es

**SQLite (DÃ©veloppement)** :
- Tables : `index_scores`, `media_articles`
- Migrations : Alembic

**PostgreSQL (Production)** :
- Support TimescaleDB pour time-series
- Optimisations pour grandes quantitÃ©s de donnÃ©es

### 4. Cache (Redis)

**ResponsabilitÃ©s** :
- Cache des requÃªtes API
- Cache des rÃ©sultats de scraping
- AmÃ©lioration des performances

**Fallback** : Cache en mÃ©moire si Redis indisponible

### 5. Scrapers

**Sources** :
- Hespress
- Medias24
- BourseNews

**Technologies** :
- BeautifulSoup
- Selenium (pour sites avec JavaScript)
- Cloudscraper (pour bypass anti-bot)

### 6. Scheduler (APScheduler)

**ResponsabilitÃ©s** :
- ExÃ©cuter le pipeline toutes les 10 minutes
- GÃ©rer les jobs rÃ©currents
- ContrÃ´le via API

---

## Flux de DonnÃ©es

### Calcul de l'Indice

```
1. Scheduler dÃ©clenche le pipeline
   â”‚
2. Pipeline Service orchestre
   â”‚
3. Market Scraper â†’ DonnÃ©es MASI
   â”‚
4. Media Scraper â†’ Articles mÃ©dias
   â”‚
5. Sentiment Analysis â†’ Scores sentiment
   â”‚
6. Component Calculator â†’ 6 composantes
   â”‚
7. Aggregator â†’ Score final (0-100)
   â”‚
8. Sauvegarde en DB
   â”‚
9. Cache mis Ã  jour
```

### RequÃªte API

```
1. Client â†’ API Endpoint
   â”‚
2. Rate Limiting Middleware
   â”‚
3. Metrics Middleware (tracking)
   â”‚
4. Authentication (si nÃ©cessaire)
   â”‚
5. Business Logic (Service)
   â”‚
6. Database Query (avec cache)
   â”‚
7. Response â†’ Client
```

---

## SÃ©curitÃ©

### Authentification

- **JWT** : Tokens pour l'authentification
- **Bcrypt** : Hash des mots de passe
- **Rate Limiting** : Protection contre les abus

### Configuration

- **SECRET_KEY** : ClÃ© secrÃ¨te pour JWT
- **CORS** : Origines autorisÃ©es
- **HTTPS** : En production (recommandÃ©)

---

## Monitoring

### MÃ©triques Prometheus

- RequÃªtes HTTP (total, durÃ©e, erreurs)
- RequÃªtes base de donnÃ©es
- OpÃ©rations de scraping
- OpÃ©rations de cache
- ExÃ©cutions de pipeline

### Health Checks

- `/monitoring/health` : SantÃ© complÃ¨te
- `/monitoring/health/database` : SantÃ© DB
- `/monitoring/stats` : Statistiques

### Logging

- **StructurÃ©** : JSON (production)
- **Standard** : Texte (dÃ©veloppement)
- **Niveaux** : DEBUG, INFO, WARNING, ERROR

---

## ScalabilitÃ©

### Horizontal

- **Load Balancer** : Distribuer les requÃªtes
- **Multiple Instances** : Backend stateless
- **Database Replication** : Pour la DB

### Vertical

- **Cache Redis** : RÃ©duire la charge DB
- **Optimisation Queries** : Index, pagination
- **Async Processing** : Jobs en arriÃ¨re-plan

---

## DÃ©ploiement

### DÃ©veloppement

```bash
# Backend
uvicorn app.main:app --reload

# Frontend
npm run dev
```

### Production

```bash
# Docker
docker-compose up -d

# Ou avec scripts
./start_all.sh
```

---

## Technologies

### Backend

- **FastAPI** : Framework web
- **SQLAlchemy** : ORM
- **Alembic** : Migrations
- **APScheduler** : Scheduler
- **Prometheus** : MÃ©triques
- **Redis** : Cache

### Frontend

- **React** : Framework UI
- **TypeScript** : Type safety
- **Tailwind CSS** : Styling
- **Recharts** : Graphiques

### Infrastructure

- **SQLite/PostgreSQL** : Base de donnÃ©es
- **Redis** : Cache
- **Docker** : Conteneurisation
- **Nginx** : Reverse proxy (optionnel)

---

## Patterns UtilisÃ©s

### Repository Pattern

Services abstraient l'accÃ¨s aux donnÃ©es.

### Dependency Injection

FastAPI gÃ¨re les dÃ©pendances automatiquement.

### Middleware Pattern

- Rate limiting
- Metrics tracking
- CORS

### Factory Pattern

CrÃ©ation de scrapers selon la source.

---

## Performance

### Optimisations

- **Cache** : RÃ©duit les requÃªtes DB
- **Pagination** : Limite les donnÃ©es retournÃ©es
- **Async** : Traitement non-bloquant
- **Connection Pooling** : RÃ©utilise les connexions DB

### MÃ©triques Cibles

- **Latence API** : < 200ms (P95)
- **Throughput** : > 100 req/s
- **Cache Hit Rate** : > 70%

---

## Ã‰volutivitÃ©

### Ajouter une Source

1. CrÃ©er un scraper dans `pipelines/ingestion/`
2. Ajouter Ã  `SOURCE_LISTINGS` dans `enhanced_media_service.py`
3. Tester et dÃ©ployer

### Ajouter une Composante

1. CrÃ©er le calculateur dans `pipelines/processing/`
2. Ajouter au `ComponentCalculator`
3. Mettre Ã  jour les poids dans `metadata`
4. CrÃ©er une migration si nÃ©cessaire

### Ajouter un Endpoint

1. CrÃ©er le fichier dans `api/v1/endpoints/`
2. Ajouter au router
3. Documenter dans `docs/API.md`

---

**ğŸ“– Pour plus de dÃ©tails, consultez les autres documents dans `docs/`.**
