# SystÃ¨me de Scraping Automatique des Rapports Financiers

## ğŸ“‹ Vue d'ensemble

Ce systÃ¨me permet de scraper automatiquement les rapports financiers officiels de toutes les entreprises cotÃ©es Ã  la Bourse de Casablanca, de les tÃ©lÃ©charger, de les uploader vers Supabase Storage, et de les afficher automatiquement sur le site.

## ğŸš€ FonctionnalitÃ©s

âœ… **Scraping automatique** des rapports depuis les sites officiels  
âœ… **TÃ©lÃ©chargement et upload** des PDFs vers Supabase Storage  
âœ… **Sauvegarde automatique** des mÃ©tadonnÃ©es dans Supabase  
âœ… **Job programmÃ©** quotidien Ã  02:00 AM  
âœ… **API REST** pour dÃ©clencher le scraping manuellement  
âœ… **DÃ©duplication** automatique (Ã©vite les doublons)  

## ğŸ“ Structure des Fichiers

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ financial_reports_scraper.py  # Service principal de scraping
â”‚   â”œâ”€â”€ api/v1/endpoints/
â”‚   â”‚   â””â”€â”€ financial_reports.py          # Endpoints API
â”‚   â””â”€â”€ tasks/
â”‚       â””â”€â”€ jobs.py                       # Job automatique
```

## ğŸ”§ Configuration

### 1. Variables d'environnement

Assurez-vous d'avoir configurÃ© Supabase dans `backend/.env` :

```bash
SUPABASE_URL=https://votre-projet.supabase.co
SUPABASE_SERVICE_KEY=votre-service-key
# ou
SUPABASE_ANON_KEY=votre-anon-key
```

### 2. Entreprises configurÃ©es

Les entreprises sont configurÃ©es dans `backend/app/services/financial_reports_scraper.py` :

```python
COMPANY_REPORTS_CONFIG = {
    'CSEMA:ATW': {
        'name': 'Attijariwafa Bank',
        'urls': [
            'https://www.attijariwafabank.com/fr/investisseurs/rapports-financiers',
        ],
        'selectors': {
            'pdf_links': 'a[href$=".pdf"]',
            'title': 'a',
        }
    },
    # ... autres entreprises
}
```

## ğŸ¯ Utilisation

### MÃ©thode 1 : Scraping Automatique (RecommandÃ©)

Le systÃ¨me s'exÃ©cute **automatiquement tous les jours Ã  02:00 AM** via le scheduler.

**Aucune action requise** - les rapports seront automatiquement :
1. ScrapÃ©s depuis les sites officiels
2. TÃ©lÃ©chargÃ©s et uploadÃ©s vers Supabase Storage
3. SauvegardÃ©s dans la table `financial_reports`
4. AffichÃ©s sur le site

### MÃ©thode 2 : DÃ©clencher via API

#### Scraper toutes les entreprises

```bash
curl -X POST "http://localhost:8001/api/v1/financial-reports/scrape" \
  -H "Content-Type: application/json" \
  -d '{
    "download_pdfs": true,
    "max_reports_per_company": 50
  }'
```

#### Scraper une entreprise spÃ©cifique

```bash
curl -X POST "http://localhost:8001/api/v1/financial-reports/scrape/CSEMA:ATW" \
  -H "Content-Type: application/json" \
  -d '{
    "download_pdfs": true,
    "max_reports": 50
  }'
```

#### Liste des entreprises configurÃ©es

```bash
curl "http://localhost:8001/api/v1/financial-reports/companies"
```

### MÃ©thode 3 : Depuis le code Python

```python
from app.services.financial_reports_scraper import FinancialReportsScraper

# Initialiser le scraper
scraper = FinancialReportsScraper()

# Scraper toutes les entreprises
stats = await scraper.scrape_all_companies(
    company_symbols=None,  # Toutes
    download_pdfs=True,
    max_reports_per_company=50
)

# Scraper une entreprise spÃ©cifique
stats = await scraper.scrape_and_save_company(
    company_symbol='CSEMA:ATW',
    download_pdfs=True,
    max_reports=50
)
```

## ğŸ“Š Format des DonnÃ©es

Chaque rapport scraper contient :

```python
{
    'company_symbol': 'CSEMA:ATW',
    'company_name': 'Attijariwafa Bank',
    'report_type': 'rapport-annuel',  # ou 'resultats', 'communique', etc.
    'title': 'Rapport Annuel 2024',
    'description': 'Rapport financier officiel de Attijariwafa Bank',
    'file_url': 'https://supabase.co/storage/.../rapport.pdf',
    'file_name': 'rapport-annuel-2024.pdf',
    'file_size': 2500000,  # en bytes
    'file_type': 'application/pdf',
    'published_at': '2024-03-15T00:00:00',
    'period_start': '2024-01-01',
    'period_end': '2024-12-31',
    'tags': ['officiel', 'scraped', 'rapport-annuel', '2024'],
    'featured': True
}
```

## ğŸ” Types de Rapports DÃ©tectÃ©s

Le systÃ¨me dÃ©tecte automatiquement le type de rapport depuis le titre/URL :

- **rapport-annuel** : Rapports annuels
- **rapport-trimestriel** : Rapports trimestriels (T1, T2, T3, T4)
- **rapport-semestriel** : Rapports semestriels (S1, S2)
- **resultats** : RÃ©sultats financiers
- **communique** : CommuniquÃ©s
- **profit-warning** : Profit warnings
- **autre** : Autres types

## ğŸ“ Ajouter une Nouvelle Entreprise

Pour ajouter une nouvelle entreprise au scraping :

1. **Trouver l'URL** de la page des rapports financiers
2. **Ajouter la configuration** dans `COMPANY_REPORTS_CONFIG` :

```python
'CSEMA:SYMBOL': {
    'name': 'Nom de l\'entreprise',
    'urls': [
        'https://www.entreprise.ma/investisseurs/rapports',
    ],
    'selectors': {
        'pdf_links': 'a[href$=".pdf"]',  # SÃ©lecteur CSS pour les liens PDF
        'title': 'a',  # SÃ©lecteur pour le titre
    }
}
```

3. **Tester** avec l'API :

```bash
curl -X POST "http://localhost:8001/api/v1/financial-reports/scrape/CSEMA:SYMBOL"
```

## ğŸ› ï¸ DÃ©pannage

### Erreur : "Supabase non configurÃ©"

**Solution** : VÃ©rifiez que `SUPABASE_URL` et `SUPABASE_SERVICE_KEY` sont dÃ©finis dans `backend/.env`

### Erreur : "Aucun PDF trouvÃ©"

**Solution** : 
1. VÃ©rifiez que l'URL de l'entreprise est correcte
2. VÃ©rifiez que le sÃ©lecteur CSS `pdf_links` est correct
3. Testez manuellement en visitant l'URL

### Erreur : "Upload Ã©chouÃ©"

**Solution** :
1. VÃ©rifiez que le bucket `documents` existe dans Supabase Storage
2. VÃ©rifiez les permissions du bucket
3. VÃ©rifiez que le fichier ne dÃ©passe pas 50MB

### Les rapports ne s'affichent pas sur le site

**Solution** :
1. VÃ©rifiez que les rapports sont bien dans Supabase (`financial_reports` table)
2. VÃ©rifiez que le frontend charge bien depuis Supabase
3. VÃ©rifiez les logs du backend pour les erreurs

## ğŸ“ˆ Monitoring

Les statistiques de scraping sont loggÃ©es :

```
âœ… Financial reports scraping completed
   - total_companies: 9
   - total_scraped: 45
   - total_downloaded: 45
   - total_saved: 45
   - total_errors: 0
```

## ğŸ”„ Workflow Complet

1. **Scraping** : Le scraper visite les URLs configurÃ©es
2. **DÃ©tection** : Les liens PDF sont dÃ©tectÃ©s via les sÃ©lecteurs CSS
3. **Analyse** : Les mÃ©tadonnÃ©es sont extraites (type, dates, tags)
4. **TÃ©lÃ©chargement** : Les PDFs sont tÃ©lÃ©chargÃ©s
5. **Upload** : Les PDFs sont uploadÃ©s vers Supabase Storage
6. **Sauvegarde** : Les mÃ©tadonnÃ©es sont sauvegardÃ©es dans `financial_reports`
7. **Affichage** : Les rapports apparaissent automatiquement sur `/reports`

## ğŸ¯ Prochaines AmÃ©liorations

- [ ] Support pour d'autres formats (DOCX, XLSX)
- [ ] Extraction de texte depuis les PDFs (OCR)
- [ ] Analyse automatique du contenu des rapports
- [ ] Notifications par email pour nouveaux rapports
- [ ] Dashboard de monitoring du scraping
- [ ] Support pour plus d'entreprises

## ğŸ“š Documentation API

Voir `/api/v1/docs` pour la documentation complÃ¨te de l'API Swagger.



