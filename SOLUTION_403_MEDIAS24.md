# ‚úÖ Solution pour Contourner le 403 Forbidden de Medias24

**Date**: Aujourd'hui  
**Probl√®me**: Medias24 retournait une erreur 403 Forbidden lors du scraping  
**Solution**: Utilisation de `cloudscraper` pour contourner les protections anti-bot

---

## üîç Probl√®me Identifi√©

Medias24 utilise une protection anti-bot sophistiqu√©e qui bloque les requ√™tes HTTP standard, m√™me avec des headers r√©alistes. Les tentatives avec `requests` standard retournaient syst√©matiquement une erreur **403 Forbidden**.

### Tentatives √âchou√©es

1. ‚ùå Headers HTTP am√©lior√©s (User-Agent, Accept-Language, etc.)
2. ‚ùå Rotation de User-Agent
3. ‚ùå Session persistante avec cookies
4. ‚ùå D√©lais entre requ√™tes
5. ‚ùå Essai de diff√©rentes URLs (homepage, √©conomie, www)

---

## ‚úÖ Solution Impl√©ment√©e

### Utilisation de `cloudscraper`

`cloudscraper` est une biblioth√®que Python sp√©cialement con√ßue pour contourner les protections anti-bot, notamment Cloudflare, mais aussi d'autres syst√®mes de protection similaires.

### Modifications Apport√©es

#### 1. Installation de cloudscraper

```bash
pip install cloudscraper
```

#### 2. Int√©gration dans le scraper Medias24

```python
# Essayer d'importer cloudscraper
try:
    import cloudscraper
    CLOUDSCRAPER_AVAILABLE = True
except ImportError:
    CLOUDSCRAPER_AVAILABLE = False
    cloudscraper = None
```

#### 3. Utilisation de cloudscraper dans le constructeur

```python
def __init__(self, delay_between_requests: int = 3, use_cloudscraper: bool = True):
    self.use_cloudscraper = use_cloudscraper and CLOUDSCRAPER_AVAILABLE
    
    if self.use_cloudscraper:
        logger.info("Utilisation de cloudscraper pour contourner les protections anti-bot")
        self.session = cloudscraper.create_scraper(
            browser={
                'browser': 'chrome',
                'platform': 'darwin',
                'desktop': True
            },
            delay=10  # D√©lai pour √©viter la d√©tection
        )
    else:
        # Fallback vers requests standard
        self.session = requests.Session()
```

#### 4. Gestion de la v√©rification SSL

Cloudscraper g√®re automatiquement la v√©rification SSL, donc on ne doit pas d√©sactiver `verify` :

```python
# Pour cloudscraper, ne pas d√©sactiver la v√©rification SSL
if self.use_cloudscraper:
    response = self.session.get(url, timeout=25, allow_redirects=True)
else:
    response = self.session.get(url, timeout=20, allow_redirects=True, verify=False)
```

---

## üìä R√©sultats

### Avant la Solution

```
‚ùå MEDIAS24: 0 articles scrap√©s
   - Erreur: 403 Forbidden
   - Toutes les tentatives √©chouaient
```

### Apr√®s la Solution

```
‚úÖ MEDIAS24: 1 article scrap√© ‚Üí 1 de qualit√©
   - cloudscraper contourne avec succ√®s la protection anti-bot
   - Articles r√©cup√©r√©s et sauvegard√©s
```

### R√©sultats Globaux

| Source | Articles Scrap√©s | Articles de Qualit√© | Statut |
|--------|------------------|---------------------|--------|
| **BourseNews** | 5 | 1 | ‚úÖ |
| **Challenge** | 1 | 1 | ‚úÖ |
| **Hespress** | 3 | 3 | ‚úÖ |
| **LaVieEco** | 0 | 0 | ‚ùå |
| **L'√âconomiste** | 2 | 2 | ‚úÖ |
| **Medias24** | 1 | 1 | ‚úÖ |

**Total**: 8 articles scrap√©s et sauvegard√©s ‚úÖ

---

## üîß Fonctionnalit√©s Ajout√©es

### 1. Rotation User-Agent (si cloudscraper non disponible)

```python
USER_AGENTS = [
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36...',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15...',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36...',
]
```

### 2. Initialisation de Session

Le scraper fait maintenant une premi√®re requ√™te pour obtenir des cookies valides avant de commencer le scraping.

### 3. Essai de Plusieurs URLs

Le scraper essaie plusieurs URLs dans l'ordre :
1. `https://medias24.com/economie` (page √©conomie)
2. `https://medias24.com` (page d'accueil)
3. `https://www.medias24.com` (page d'accueil avec www)

### 4. Fallback Intelligent

Si cloudscraper n'est pas disponible, le scraper utilise `requests` standard avec toutes les optimisations (headers, rotation User-Agent, etc.).

---

## üìù Utilisation

### Utilisation Standard (avec cloudscraper)

```python
from app.pipelines.ingestion.medias24_scraper import Medias24Scraper

scraper = Medias24Scraper(delay_between_requests=3, use_cloudscraper=True)
articles = scraper.fetch_articles(max_articles=10)
```

### Utilisation sans cloudscraper (fallback)

```python
scraper = Medias24Scraper(delay_between_requests=3, use_cloudscraper=False)
articles = scraper.fetch_articles(max_articles=10)
```

---

## ‚ö†Ô∏è Notes Importantes

1. **Respect des Conditions d'Utilisation** : Assurez-vous de respecter les conditions d'utilisation de Medias24 et ne pas surcharger leurs serveurs.

2. **D√©lais Recommand√©s** : Utilisez un d√©lai d'au moins 3 secondes entre les requ√™tes pour √©viter la d√©tection.

3. **Cloudscraper** : Cette biblioth√®que est sp√©cialement con√ßue pour contourner les protections anti-bot, mais elle peut √™tre plus lente que `requests` standard.

4. **Maintenance** : Les protections anti-bot √©voluent, donc la solution peut n√©cessiter des mises √† jour √† l'avenir.

---

## üöÄ Conclusion

La solution avec `cloudscraper` permet de contourner avec succ√®s le 403 Forbidden de Medias24. Le syst√®me de scraping fonctionne maintenant pour **5 sources sur 6**, avec un total de **8 articles scrap√©s et sauvegard√©s**.

**Medias24 est maintenant op√©rationnel !** ‚úÖ




